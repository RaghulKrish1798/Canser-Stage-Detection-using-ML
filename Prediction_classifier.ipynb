{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import gc\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from misl_dataset import train_valid_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the Stage Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count           119\n",
       "unique           10\n",
       "top       stage iia\n",
       "freq             38\n",
       "Name: stage, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_list =  os.listdir('C:/Users/RaghulKrish/Desktop/UB/Spring_23/CVIP/Project/extracted_features/')\n",
    "# patient_list = \n",
    "fixed_patient_list = [x[:-8] for x in patient_list]\n",
    "fixed_patient_list = [p.lower() for p in fixed_patient_list]\n",
    "total_stages = pd.read_csv('C:/Users/RaghulKrish/Desktop/UB/Spring_23/CVIP/Project/BRCA_stages.csv', delimiter=\",\")\n",
    "mask = total_stages['pid'].isin(fixed_patient_list)\n",
    "total_stages = total_stages.drop(total_stages[~mask].index)\n",
    "\n",
    "# trimmable_patients = total_stages.loc[total_stages['pid'] not in fixed_patient_list].index\n",
    "# total_stages.drop(index=trimmable_patients, inplace=True)\n",
    "# trimmable_patients = total_stages.loc[total_stages['pid'] not in patient_list].index\n",
    "# total_stages.drop(index=trimmable_patients.values, inplace=True)\n",
    "\n",
    "total_stages['stage'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcga-bh-a0b2\n",
      "tcga-d8-a13z\n"
     ]
    }
   ],
   "source": [
    "for i in fixed_patient_list:\n",
    "    if i not in total_stages['pid'].values:\n",
    "        print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the Clustered Data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/RaghulKrish/Desktop/UB/Spring_23/CVIP/Project/clustered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>cluster_num</th>\n",
       "      <th>pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.461104</td>\n",
       "      <td>-0.285967</td>\n",
       "      <td>-1.397519</td>\n",
       "      <td>0.229647</td>\n",
       "      <td>0.936981</td>\n",
       "      <td>3.368677</td>\n",
       "      <td>3.793468</td>\n",
       "      <td>-0.550289</td>\n",
       "      <td>1.107400</td>\n",
       "      <td>-2.729292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022788</td>\n",
       "      <td>0.624529</td>\n",
       "      <td>0.861521</td>\n",
       "      <td>-0.310676</td>\n",
       "      <td>1.878729</td>\n",
       "      <td>-0.246086</td>\n",
       "      <td>-0.164000</td>\n",
       "      <td>2.957375</td>\n",
       "      <td>7</td>\n",
       "      <td>tcga-a1-a0sb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.799152</td>\n",
       "      <td>0.231676</td>\n",
       "      <td>-0.894569</td>\n",
       "      <td>0.052585</td>\n",
       "      <td>0.519808</td>\n",
       "      <td>1.227673</td>\n",
       "      <td>2.117962</td>\n",
       "      <td>-0.776678</td>\n",
       "      <td>-0.071368</td>\n",
       "      <td>-1.076421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.977934</td>\n",
       "      <td>-1.083503</td>\n",
       "      <td>-0.853440</td>\n",
       "      <td>-0.938821</td>\n",
       "      <td>1.287605</td>\n",
       "      <td>-0.965848</td>\n",
       "      <td>-0.061129</td>\n",
       "      <td>1.716388</td>\n",
       "      <td>3</td>\n",
       "      <td>tcga-a1-a0sb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.118939</td>\n",
       "      <td>0.161997</td>\n",
       "      <td>-1.180829</td>\n",
       "      <td>-0.175141</td>\n",
       "      <td>0.825578</td>\n",
       "      <td>2.004492</td>\n",
       "      <td>2.922759</td>\n",
       "      <td>-0.734270</td>\n",
       "      <td>0.828440</td>\n",
       "      <td>-1.833263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.741320</td>\n",
       "      <td>-1.726206</td>\n",
       "      <td>-0.900631</td>\n",
       "      <td>-1.783865</td>\n",
       "      <td>-0.284666</td>\n",
       "      <td>-0.169607</td>\n",
       "      <td>0.134723</td>\n",
       "      <td>3.002424</td>\n",
       "      <td>1</td>\n",
       "      <td>tcga-a1-a0sb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.516077</td>\n",
       "      <td>0.166150</td>\n",
       "      <td>-1.896911</td>\n",
       "      <td>-0.896396</td>\n",
       "      <td>-0.133664</td>\n",
       "      <td>1.366326</td>\n",
       "      <td>1.961223</td>\n",
       "      <td>-0.625198</td>\n",
       "      <td>0.875285</td>\n",
       "      <td>-1.964036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.618743</td>\n",
       "      <td>-2.314713</td>\n",
       "      <td>-0.857852</td>\n",
       "      <td>-1.888762</td>\n",
       "      <td>-0.840151</td>\n",
       "      <td>-0.670046</td>\n",
       "      <td>0.701192</td>\n",
       "      <td>2.627288</td>\n",
       "      <td>1</td>\n",
       "      <td>tcga-a1-a0sb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.132791</td>\n",
       "      <td>-0.133278</td>\n",
       "      <td>-0.793486</td>\n",
       "      <td>0.366926</td>\n",
       "      <td>1.200107</td>\n",
       "      <td>1.700159</td>\n",
       "      <td>2.119426</td>\n",
       "      <td>-1.155944</td>\n",
       "      <td>-0.424008</td>\n",
       "      <td>-1.007438</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.015913</td>\n",
       "      <td>0.863694</td>\n",
       "      <td>-0.787496</td>\n",
       "      <td>0.022276</td>\n",
       "      <td>2.507776</td>\n",
       "      <td>-1.241899</td>\n",
       "      <td>-0.154245</td>\n",
       "      <td>1.791794</td>\n",
       "      <td>3</td>\n",
       "      <td>tcga-a1-a0sb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -1.461104 -0.285967 -1.397519  0.229647  0.936981  3.368677  3.793468   \n",
       "1 -0.799152  0.231676 -0.894569  0.052585  0.519808  1.227673  2.117962   \n",
       "2 -1.118939  0.161997 -1.180829 -0.175141  0.825578  2.004492  2.922759   \n",
       "3 -0.516077  0.166150 -1.896911 -0.896396 -0.133664  1.366326  1.961223   \n",
       "4 -2.132791 -0.133278 -0.793486  0.366926  1.200107  1.700159  2.119426   \n",
       "\n",
       "          7         8         9  ...       992       993       994       995  \\\n",
       "0 -0.550289  1.107400 -2.729292  ...  0.022788  0.624529  0.861521 -0.310676   \n",
       "1 -0.776678 -0.071368 -1.076421  ... -0.977934 -1.083503 -0.853440 -0.938821   \n",
       "2 -0.734270  0.828440 -1.833263  ... -0.741320 -1.726206 -0.900631 -1.783865   \n",
       "3 -0.625198  0.875285 -1.964036  ... -0.618743 -2.314713 -0.857852 -1.888762   \n",
       "4 -1.155944 -0.424008 -1.007438  ... -1.015913  0.863694 -0.787496  0.022276   \n",
       "\n",
       "        996       997       998       999  cluster_num           pid  \n",
       "0  1.878729 -0.246086 -0.164000  2.957375            7  tcga-a1-a0sb  \n",
       "1  1.287605 -0.965848 -0.061129  1.716388            3  tcga-a1-a0sb  \n",
       "2 -0.284666 -0.169607  0.134723  3.002424            1  tcga-a1-a0sb  \n",
       "3 -0.840151 -0.670046  0.701192  2.627288            1  tcga-a1-a0sb  \n",
       "4  2.507776 -1.241899 -0.154245  1.791794            3  tcga-a1-a0sb  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.drop(df.columns[0], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pid = df['pid']\n",
    "cluster_num = df['cluster_num']\n",
    "df = df.drop(['pid', 'cluster_num'], axis=1)\n",
    "scaler.fit(df)\n",
    "n_df = scaler.transform(df)\n",
    "df = pd.DataFrame(n_df, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>pid</th>\n",
       "      <th>cluster_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.717710</td>\n",
       "      <td>-1.581317</td>\n",
       "      <td>-1.057331</td>\n",
       "      <td>-0.638967</td>\n",
       "      <td>-0.404404</td>\n",
       "      <td>0.659463</td>\n",
       "      <td>0.191061</td>\n",
       "      <td>0.352148</td>\n",
       "      <td>0.904366</td>\n",
       "      <td>-1.410457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061712</td>\n",
       "      <td>1.267137</td>\n",
       "      <td>0.157217</td>\n",
       "      <td>0.095518</td>\n",
       "      <td>0.922479</td>\n",
       "      <td>-0.158488</td>\n",
       "      <td>-0.994116</td>\n",
       "      <td>-0.224805</td>\n",
       "      <td>tcga-a1-a0sb</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.018819</td>\n",
       "      <td>-0.940304</td>\n",
       "      <td>-0.713356</td>\n",
       "      <td>-0.770011</td>\n",
       "      <td>-0.699232</td>\n",
       "      <td>-1.108700</td>\n",
       "      <td>-0.866002</td>\n",
       "      <td>0.053147</td>\n",
       "      <td>-0.388176</td>\n",
       "      <td>0.808984</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.088802</td>\n",
       "      <td>-0.059723</td>\n",
       "      <td>-1.049583</td>\n",
       "      <td>-0.500579</td>\n",
       "      <td>0.513526</td>\n",
       "      <td>-0.853950</td>\n",
       "      <td>-0.892466</td>\n",
       "      <td>-1.296506</td>\n",
       "      <td>tcga-a1-a0sb</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.356451</td>\n",
       "      <td>-1.026590</td>\n",
       "      <td>-0.909133</td>\n",
       "      <td>-0.938551</td>\n",
       "      <td>-0.483136</td>\n",
       "      <td>-0.467159</td>\n",
       "      <td>-0.358262</td>\n",
       "      <td>0.109157</td>\n",
       "      <td>0.598482</td>\n",
       "      <td>-0.207288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.816771</td>\n",
       "      <td>-0.558997</td>\n",
       "      <td>-1.082791</td>\n",
       "      <td>-1.302507</td>\n",
       "      <td>-0.574204</td>\n",
       "      <td>-0.084591</td>\n",
       "      <td>-0.698940</td>\n",
       "      <td>-0.185901</td>\n",
       "      <td>tcga-a1-a0sb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.280051</td>\n",
       "      <td>-1.021447</td>\n",
       "      <td>-1.398873</td>\n",
       "      <td>-1.472354</td>\n",
       "      <td>-1.161060</td>\n",
       "      <td>-0.994193</td>\n",
       "      <td>-0.964888</td>\n",
       "      <td>0.253212</td>\n",
       "      <td>0.649848</td>\n",
       "      <td>-0.382888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675846</td>\n",
       "      <td>-1.016170</td>\n",
       "      <td>-1.052688</td>\n",
       "      <td>-1.402053</td>\n",
       "      <td>-0.958500</td>\n",
       "      <td>-0.568134</td>\n",
       "      <td>-0.139195</td>\n",
       "      <td>-0.509864</td>\n",
       "      <td>tcga-a1-a0sb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.426878</td>\n",
       "      <td>-1.392238</td>\n",
       "      <td>-0.644224</td>\n",
       "      <td>-0.537366</td>\n",
       "      <td>-0.218445</td>\n",
       "      <td>-0.718494</td>\n",
       "      <td>-0.865079</td>\n",
       "      <td>-0.447765</td>\n",
       "      <td>-0.774852</td>\n",
       "      <td>0.901613</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.132467</td>\n",
       "      <td>1.452929</td>\n",
       "      <td>-1.003179</td>\n",
       "      <td>0.411483</td>\n",
       "      <td>1.357666</td>\n",
       "      <td>-1.120681</td>\n",
       "      <td>-0.984477</td>\n",
       "      <td>-1.231387</td>\n",
       "      <td>tcga-a1-a0sb</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.717710 -1.581317 -1.057331 -0.638967 -0.404404  0.659463  0.191061   \n",
       "1 -0.018819 -0.940304 -0.713356 -0.770011 -0.699232 -1.108700 -0.866002   \n",
       "2 -0.356451 -1.026590 -0.909133 -0.938551 -0.483136 -0.467159 -0.358262   \n",
       "3  0.280051 -1.021447 -1.398873 -1.472354 -1.161060 -0.994193 -0.964888   \n",
       "4 -1.426878 -1.392238 -0.644224 -0.537366 -0.218445 -0.718494 -0.865079   \n",
       "\n",
       "          7         8         9  ...       992       993       994       995  \\\n",
       "0  0.352148  0.904366 -1.410457  ...  0.061712  1.267137  0.157217  0.095518   \n",
       "1  0.053147 -0.388176  0.808984  ... -1.088802 -0.059723 -1.049583 -0.500579   \n",
       "2  0.109157  0.598482 -0.207288  ... -0.816771 -0.558997 -1.082791 -1.302507   \n",
       "3  0.253212  0.649848 -0.382888  ... -0.675846 -1.016170 -1.052688 -1.402053   \n",
       "4 -0.447765 -0.774852  0.901613  ... -1.132467  1.452929 -1.003179  0.411483   \n",
       "\n",
       "        996       997       998       999           pid  cluster_num  \n",
       "0  0.922479 -0.158488 -0.994116 -0.224805  tcga-a1-a0sb            7  \n",
       "1  0.513526 -0.853950 -0.892466 -1.296506  tcga-a1-a0sb            3  \n",
       "2 -0.574204 -0.084591 -0.698940 -0.185901  tcga-a1-a0sb            1  \n",
       "3 -0.958500 -0.568134 -0.139195 -0.509864  tcga-a1-a0sb            1  \n",
       "4  1.357666 -1.120681 -0.984477 -1.231387  tcga-a1-a0sb            3  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pid'] = pid\n",
    "df['cluster_num'] = cluster_num\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 10\n",
    "# for patient in fixed_patient_list:\n",
    "mask = (df['pid'] == fixed_patient_list[1]) | (df['pid'] == fixed_patient_list[8])\n",
    "patient_data = df.loc[mask]\n",
    "\n",
    "patient_cluster = []\n",
    "for i in range(num_clusters):\n",
    "    m = patient_data['cluster_num'] == i\n",
    "    data = (patient_data.loc[m]).drop(['pid', 'cluster_num'], axis=1)\n",
    "    # data = torch.tensor(data.values, dtype=torch.float32)\n",
    "    patient_cluster.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class DeepAttnMIL_Surv(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep AttnMISL Model definition\n",
    "    \"\"\"\n",
    "    def __init__(self, cluster_num):\n",
    "        super(DeepAttnMIL_Surv, self).__init__()\n",
    "        self.embedding_net = nn.Sequential(nn.Conv1d(1000, 64, 1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.AdaptiveAvgPool1d(1)\n",
    "                                     )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(64, 32), # V\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 1)  # W\n",
    "        )\n",
    "\n",
    "        self.fc6 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(32,10)\n",
    "        )\n",
    "        self.cluster_num = cluster_num\n",
    "\n",
    "    def masked_softmax(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Performs masked softmax, as simply masking post-softmax can be\n",
    "        inaccurate\n",
    "        :param x: [batch_size, num_items]\n",
    "        :param mask: [batch_size, num_items]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if mask is not None:\n",
    "            mask = mask.float()\n",
    "        if mask is not None:\n",
    "            x_masked = x * mask + (1 - 1 / (mask+1e-5))\n",
    "        else:\n",
    "            x_masked = x\n",
    "        x_max = x_masked.max(1)[0]\n",
    "        x_exp = (x - x_max.unsqueeze(-1)).exp()\n",
    "        if mask is not None:\n",
    "            x_exp = x_exp * mask.float()\n",
    "        return x_exp / x_exp.sum(1).unsqueeze(-1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "\n",
    "        \" x is a tensor list\"\n",
    "        res = []\n",
    "        for i in range(self.cluster_num):\n",
    "                \n",
    "            hh = x[i]\n",
    "            \n",
    "            hh = hh.unsqueeze(0).reshape(1, 1000, len(hh))\n",
    "            \n",
    "            output = self.embedding_net(hh)\n",
    "            \n",
    "            output = output.view(output.size()[0], -1)\n",
    "            \n",
    "            res.append(output)\n",
    "\n",
    "        h = torch.cat(res)\n",
    "\n",
    "        b = h.size(0)\n",
    "        c = h.size(1)\n",
    "\n",
    "        h = h.view(b, c)\n",
    "        \n",
    "        A = self.attention(h)\n",
    "        A = torch.transpose(A, 1, 0)  # KxN\n",
    "        \n",
    "        A = self.masked_softmax(A, mask)\n",
    "\n",
    "        M = torch.mm(A, h)  # KxL\n",
    "\n",
    "        Y_pred = self.fc6(M)\n",
    "\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0873,  0.1594, -0.2427, -0.0486, -0.1489, -0.1344,  0.1191, -0.0211,\n",
      "         -0.1297,  0.0856]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = DeepAttnMIL_Surv(cluster_num = num_clusters).cuda()\n",
    "tensor_list = [torch.tensor(df.values, dtype=torch.float32) for df in patient_cluster]\n",
    "tensor_list = [tensor.to(device) for tensor in tensor_list]\n",
    "               \n",
    "mask = np.ones(num_clusters, dtype=np.float32)\n",
    "for i in cluster_num:\n",
    "    if len(patient_cluster[i]) == 0:\n",
    "        mask[i] = 0\n",
    "        tensor_list[i] = torch.tensor(np.zeros((1, 1000), dtype = np.float32)).to(device)\n",
    "mask = torch.tensor(mask, dtype=torch.float32)\n",
    "masked_cls = mask.cuda()\n",
    "# print(mask)\n",
    "# tensor_list[0].shape\n",
    "lbl_pred = model(tensor_list, masked_cls)  # prediction\n",
    "print(lbl_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import gc\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from misl_dataset import train_valid_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 1\n",
    "lr = 0.001\n",
    "num_clusters = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class DeepAttnMIL_Surv(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep AttnMISL Model definition\n",
    "    \"\"\"\n",
    "    def __init__(self, cluster_num):\n",
    "        super(DeepAttnMIL_Surv, self).__init__()\n",
    "        self.embedding_net = nn.Sequential(nn.Conv1d(1000, 64, 1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.AdaptiveAvgPool1d(1)\n",
    "                                     )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(64, 32), # V\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 1)  # W\n",
    "        )\n",
    "\n",
    "        self.fc6 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(32,2)\n",
    "        )\n",
    "        self.cluster_num = cluster_num\n",
    "\n",
    "    def masked_softmax(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Performs masked softmax, as simply masking post-softmax can be\n",
    "        inaccurate\n",
    "        :param x: [batch_size, num_items]\n",
    "        :param mask: [batch_size, num_items]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if mask is not None:\n",
    "            mask = mask.float()\n",
    "        if mask is not None:\n",
    "            x_masked = x * mask + (1 - 1 / (mask+1e-5))\n",
    "        else:\n",
    "            x_masked = x\n",
    "        x_max = x_masked.max(1)[0]\n",
    "        x_exp = (x - x_max.unsqueeze(-1)).exp()\n",
    "        if mask is not None:\n",
    "            x_exp = x_exp * mask.float()\n",
    "        return x_exp / x_exp.sum(1).unsqueeze(-1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "\n",
    "        \" x is a tensor list\"\n",
    "        res = []\n",
    "        for i in range(self.cluster_num):\n",
    "                \n",
    "            hh = x[i]\n",
    "            \n",
    "            hh = hh.unsqueeze(0).reshape(1, 1000, len(hh))\n",
    "            \n",
    "            output = self.embedding_net(hh)\n",
    "            \n",
    "            output = output.view(output.size()[0], -1)\n",
    "            \n",
    "            res.append(output)\n",
    "\n",
    "        h = torch.cat(res)\n",
    "\n",
    "        b = h.size(0)\n",
    "        c = h.size(1)\n",
    "\n",
    "        h = h.view(b, c)\n",
    "        \n",
    "        A = self.attention(h)\n",
    "        A = torch.transpose(A, 1, 0)  # KxN\n",
    "        \n",
    "        A = self.masked_softmax(A, mask)\n",
    "\n",
    "        M = torch.mm(A, h)  # KxL\n",
    "\n",
    "        Y_pred = self.fc6(M)\n",
    "\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tcga-a1-a0sf' 'tcga-a1-a0sf' 'tcga-a1-a0sf' ... 'tcga-ll-a5yl'\n",
      " 'tcga-ll-a5yl' 'tcga-ll-a5yl']\n",
      "['tcga-a1-a0sf' 'tcga-a1-a0sk' 'tcga-a2-a25c' 'tcga-a7-a3rf'\n",
      " 'tcga-a8-a06z' 'tcga-a8-a0a2' 'tcga-ac-a23e' 'tcga-ac-a8op'\n",
      " 'tcga-ar-a0tp' 'tcga-ar-a24h' 'tcga-ar-a2ll' 'tcga-bh-a1fg'\n",
      " 'tcga-d8-a1jb' 'tcga-e9-a1n9' 'tcga-e9-a1nc' 'tcga-e9-a244'\n",
      " 'tcga-ll-a5yl']\n",
      "['tcga-a2-a0eq' 'tcga-a2-a0eq' 'tcga-a2-a0eq' ... 'tcga-gm-a3ny'\n",
      " 'tcga-gm-a3ny' 'tcga-gm-a3ny']\n",
      "['tcga-a2-a0eq' 'tcga-a2-a0ym' 'tcga-a8-a07s' 'tcga-bh-a0hf'\n",
      " 'tcga-bh-a0wa' 'tcga-bh-a18v' 'tcga-bh-a1f5' 'tcga-bh-a1fe'\n",
      " 'tcga-d8-a1ji' 'tcga-d8-a1xb' 'tcga-d8-a1xo' 'tcga-e2-a105'\n",
      " 'tcga-ew-a6sd' 'tcga-gm-a3ny']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kasraborazjani/Desktop/UB/Spring 2023/CSE573 Course Project/CSE573-Final-Project/misl_dataset.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.labels['stage'] = self.labels.stage.map(lambda x: one_hot_binary(x))\n"
     ]
    }
   ],
   "source": [
    "# Kasra's use\n",
    "data_path = './clustered_data.csv'\n",
    "label_path = './BRCA_stages.csv'\n",
    "\n",
    "# Raghul's use\n",
    "# data_path = 'C:/Users/RaghulKrish/Desktop/UB/Spring_23/CVIP/Project/clustered_data.csv'\n",
    "# label_path = 'C:/Users/RaghulKrish/Desktop/UB/Spring_23/CVIP/Project/BRCA_stages.csv'\n",
    "\n",
    "train_data, valid_data, test_data = train_valid_test_split(data_path, label_path, 0.2, 0.2)\n",
    "\n",
    "# train_loader = DataLoader(train_data, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "# test_loader = DataLoader(test_data, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "# valid_loader = DataLoader(valid_data, batch_size, shuffle = True, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ---> Epoch Loss: 0.5693424940109253\n",
      "epoch: 0, Validation loss: 0.48624521493911743, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 1, Validation loss: 0.5055654048919678, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 2, Validation loss: 0.4429421126842499, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 3, Validation loss: 0.3590315282344818, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 4, Validation loss: 0.48816296458244324, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 5, Validation loss: 0.4161360561847687, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 6, Validation loss: 0.5017899870872498, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 7, Validation loss: 0.3900062143802643, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 8, Validation loss: 0.5173165798187256, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 9, Validation loss: 0.5115259289741516, Validation Accuracy: 85.71428571428571%\n",
      "Epoch: 10 ---> Epoch Loss: 0.3275754749774933\n",
      "epoch: 10, Validation loss: 0.5386656522750854, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 11, Validation loss: 0.4778779149055481, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 12, Validation loss: 0.5043929219245911, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 13, Validation loss: 0.42871978878974915, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 14, Validation loss: 0.412579745054245, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 15, Validation loss: 0.7264065742492676, Validation Accuracy: 78.57142857142857%\n",
      "epoch: 16, Validation loss: 0.6477242708206177, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 17, Validation loss: 0.7878065705299377, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 18, Validation loss: 0.7303080558776855, Validation Accuracy: 78.57142857142857%\n",
      "epoch: 19, Validation loss: 0.6057119369506836, Validation Accuracy: 85.71428571428571%\n",
      "Epoch: 20 ---> Epoch Loss: 0.10082711279392242\n",
      "epoch: 20, Validation loss: 1.1379746198654175, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 21, Validation loss: 0.9404992461204529, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 22, Validation loss: 1.0565788745880127, Validation Accuracy: 78.57142857142857%\n",
      "epoch: 23, Validation loss: 1.2701371908187866, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 24, Validation loss: 0.9051972031593323, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 25, Validation loss: 0.6723393201828003, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 26, Validation loss: 1.299378514289856, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 27, Validation loss: 0.8591198921203613, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 28, Validation loss: 0.9655150175094604, Validation Accuracy: 85.71428571428571%\n",
      "epoch: 29, Validation loss: 0.9567471146583557, Validation Accuracy: 78.57142857142857%\n"
     ]
    }
   ],
   "source": [
    "model = DeepAttnMIL_Surv(cluster_num = num_clusters).to(device)\n",
    "model.train()\n",
    "\n",
    "train_loss = []\n",
    "loss_valid = []\n",
    "acc_val = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr, weight_decay = 0.005, momentum = 0.9)\n",
    "\n",
    "def predict(batch, label):\n",
    "    patient, mask = batch\n",
    "    for cluster_id in range(len(patient)):\n",
    "        patient[cluster_id] = patient[cluster_id].to(device)\n",
    "    mask = mask.to(device)\n",
    "    label = label.to(device)\n",
    "\n",
    "    output = model(patient, mask)\n",
    "    label.unsqueeze_(0)\n",
    "    loss = criterion(output, label)\n",
    "    output = output.to(\"cpu\")\n",
    "    y_pred = np.argmax(np.array(output), axis = 1)\n",
    "    label = label.to(\"cpu\")\n",
    "    label = np.argmax(label, axis = 1)\n",
    "    acc = accuracy(y_pred, label) \n",
    "    return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "def accuracy(y_pred, labels):\n",
    "    return np.sum(y_pred == labels.numpy()) / labels.shape[0] * 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    epoch_loss = []\n",
    "    for batch_idx, (batch, label) in enumerate(train_data):\n",
    "        patient, mask = batch\n",
    "        for cluster_id in range(len(patient)):\n",
    "            patient[cluster_id] = patient[cluster_id].to(device)\n",
    "        label = label.to(device)\n",
    "        mask = mask.to(device)\n",
    "\n",
    "        output = model(patient, mask)\n",
    "        # print(output.shape)\n",
    "        # print(label.shape)\n",
    "        label.unsqueeze_(0)\n",
    "        loss = criterion(output, label)\n",
    "        epoch_loss.append(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = torch.stack(epoch_loss)\n",
    "    epoch_loss = epoch_loss.to(\"cpu\").detach().numpy().mean()\n",
    "    # epoch_loss = epoch_loss\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} ---> Epoch Loss: {epoch_loss}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        valid_op = [predict(batch, label) for batch_idx, (batch, label) in enumerate(valid_data)]\n",
    "        batch_losses = [x['val_loss'] for x in valid_op]\n",
    "        valid_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in valid_op]\n",
    "        valid_acc = (np.array(batch_accs)).mean()\n",
    "        acc_val.append(valid_acc)\n",
    "        loss_valid.append(valid_loss)\n",
    "        print(f\"epoch: {i}, Validation loss: {valid_loss}, Validation Accuracy: {valid_acc}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('mmfl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "910b217ae2be209feb0550a453476b9fbb23d00fa51caa8a263311d4917bb429"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
